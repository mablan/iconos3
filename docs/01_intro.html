<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Magdiel Ablan" />


<title>Análisis exploratorio de datos</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="01_intro.html">Exploración</a>
</li>
<li>
  <a href="recursos.html">Recursos</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">Créditos</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Análisis exploratorio de datos</h1>
<h3 class="subtitle">Amazon reviews</h3>
<h4 class="author">Magdiel Ablan</h4>
<h4 class="date">8/12/2020</h4>

</div>


<div id="introducción" class="section level1">
<h1><span class="header-section-number">1</span> Introducción</h1>
<p>A continuación realizamos un análisis exploratorio de datos del conjunto de datos de <a href="https://www.kaggle.com/kashnitsky/hierarchical-text-classification">revisión de productos de Amazon</a> que se encuentra en Kaggle.</p>
<p>La idea es usar este conjunto de datos como un <em>proxy</em> que permita aproximarnos al problema de clasificar documentos planteado en el proyecto <strong>iconos</strong>.</p>
<p>Este conjunto de datos tiene tres niveles o categorías de clasificación:</p>
<ol style="list-style-type: decimal">
<li>Nivel 1: 6 clases</li>
<li>Nivel 2: 64 clases</li>
<li>Nivel 3: 510 clases</li>
</ol>
<p>y tres conjuntos de datos:</p>
<ul>
<li>train_40k.csv: para entrenamiento 40000 registros</li>
<li>valid_10k.csv: para validación 10000 registros</li>
<li>unlabeled_150k.csv: 150000 registros sin etiqueta</li>
</ul>
<p>El análisis exploratorio lo vamos a realizar con el conjunto de entrenamiento y por el momento con el primer nivel de clasificación.</p>
<p>Las variables que tiene son:</p>
<ul>
<li>product_id</li>
<li>title</li>
<li>user_id</li>
<li>helpfulness</li>
<li>score</li>
<li>time</li>
<li>text</li>
<li>cat1</li>
<li>cat2</li>
<li>cat3</li>
</ul>
</div>
<div id="ingestión-de-datos" class="section level1">
<h1><span class="header-section-number">2</span> Ingestión de datos</h1>
<pre class="r"><code>train_40k &lt;- read_csv(&quot;datos/train_40k.csv&quot;) %&gt;% 
  clean_names()</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   productId = col_character(),
##   Title = col_character(),
##   userId = col_character(),
##   Helpfulness = col_character(),
##   Score = col_double(),
##   Time = col_double(),
##   Text = col_character(),
##   Cat1 = col_character(),
##   Cat2 = col_character(),
##   Cat3 = col_character()
## )</code></pre>
<pre class="r"><code>glimpse(train_40k)</code></pre>
<pre><code>## Rows: 40,000
## Columns: 10
## $ product_id  &lt;chr&gt; &quot;B000E46LYG&quot;, &quot;B000GRA6N8&quot;, &quot;B000GRA6N8&quot;, &quot;B000GRA6N8&quot;, &quot;…
## $ title       &lt;chr&gt; &quot;Golden Valley Natural Buffalo Jerky&quot;, &quot;Westing Game&quot;, &quot;W…
## $ user_id     &lt;chr&gt; &quot;A3MQDNGHDJU4MK&quot;, &quot;unknown&quot;, &quot;unknown&quot;, &quot;unknown&quot;, &quot;unkno…
## $ helpfulness &lt;chr&gt; &quot;0/0&quot;, &quot;0/0&quot;, &quot;0/0&quot;, &quot;0/0&quot;, &quot;2/4&quot;, &quot;2/2&quot;, &quot;1/1&quot;, &quot;1/6&quot;, &quot;…
## $ score       &lt;dbl&gt; 3, 5, 5, 5, 5, 5, 4, 3, 5, 5, 5, 1, 5, 5, 5, 4, 5, 5, 5, …
## $ time        &lt;dbl&gt; -1, 860630400, 883008000, 897696000, 911865600, 912816000…
## $ text        &lt;chr&gt; &quot;The description and photo on this product needs to be ch…
## $ cat1        &lt;chr&gt; &quot;grocery gourmet food&quot;, &quot;toys games&quot;, &quot;toys games&quot;, &quot;toys…
## $ cat2        &lt;chr&gt; &quot;meat poultry&quot;, &quot;games&quot;, &quot;games&quot;, &quot;games&quot;, &quot;puzzles&quot;, &quot;ga…
## $ cat3        &lt;chr&gt; &quot;jerky&quot;, &quot;unknown&quot;, &quot;unknown&quot;, &quot;unknown&quot;, &quot;jigsaw puzzles…</code></pre>
<p>Para evitar problemas de memoria más adelante, se crea una muestra de 20000 observaciones del conjunto de entrenamiento. Con eso vamos a trabajar:</p>
<pre class="r"><code>set.seed(1234)
ind_20k &lt;- sample(1:40000,size = 20000,replace = FALSE)
train_20k &lt;- train_40k[ind_20k,]</code></pre>
<p>Añadimos un <code>id</code> a los registros y seleccionamos solo el texto y la categoría 1</p>
<pre class="r"><code>n_reviews &lt;- dim(train_20k)[1]
id &lt;- 1:n_reviews

text_cat1 &lt;- train_20k %&gt;%
  select(product_id,text,cat1) %&gt;% 
  mutate(id = id)

glimpse(text_cat1)</code></pre>
<pre><code>## Rows: 20,000
## Columns: 4
## $ product_id &lt;chr&gt; &quot;B0006SKCVI&quot;, &quot;B00011K2BA&quot;, &quot;B0005Z86KQ&quot;, &quot;B000DZAXGS&quot;, &quot;B…
## $ text       &lt;chr&gt; &quot;Huey Fong Chili Garlic Sauce 8 OzThis sauce made of crush…
## $ cat1       &lt;chr&gt; &quot;grocery gourmet food&quot;, &quot;health personal care&quot;, &quot;grocery g…
## $ id         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…</code></pre>
<p>Contamos cuantos registros tenemos en cada categoría:</p>
<pre class="r"><code>text_cat1 %&gt;% 
  group_by(cat1) %&gt;% 
  tally()</code></pre>
<pre><code>## # A tibble: 6 x 2
##   cat1                     n
##   &lt;chr&gt;                &lt;int&gt;
## 1 baby products         2802
## 2 beauty                2894
## 3 grocery gourmet food  1803
## 4 health personal care  4907
## 5 pet supplies          2464
## 6 toys games            5130</code></pre>
<p>Extraemos las palabras en el texto:</p>
<pre class="r"><code>palabras &lt;- text_cat1 %&gt;%
  unnest_tokens(word,text)

glimpse(palabras)</code></pre>
<pre><code>## Rows: 1,657,994
## Columns: 4
## $ product_id &lt;chr&gt; &quot;B0006SKCVI&quot;, &quot;B0006SKCVI&quot;, &quot;B0006SKCVI&quot;, &quot;B0006SKCVI&quot;, &quot;B…
## $ cat1       &lt;chr&gt; &quot;grocery gourmet food&quot;, &quot;grocery gourmet food&quot;, &quot;grocery g…
## $ id         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ word       &lt;chr&gt; &quot;huey&quot;, &quot;fong&quot;, &quot;chili&quot;, &quot;garlic&quot;, &quot;sauce&quot;, &quot;8&quot;, &quot;ozthis&quot;,…</code></pre>
<p>y excluimos las palabras vacías</p>
<pre class="r"><code>data(stop_words)
palabras &lt;- palabras %&gt;% 
  anti_join(stop_words)</code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<p>Calculamos la frecuencia de palabras en orden descendente</p>
<pre class="r"><code>palabras %&gt;% 
  count(word, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 41,620 x 2
##    word          n
##    &lt;chr&gt;     &lt;int&gt;
##  1 product    6062
##  2 time       3970
##  3 love       3453
##  4 bought     3199
##  5 toy        2945
##  6 hair       2767
##  7 2          2608
##  8 buy        2182
##  9 easy       2067
## 10 recommend  2055
## # … with 41,610 more rows</code></pre>
<p>y las visualizamos:</p>
<pre class="r"><code>palabras %&gt;% 
  count(word, sort = TRUE) %&gt;% 
  filter(n &gt; 2000) %&gt;% 
  mutate(word = reorder(word,n)) %&gt;% 
  ggplot(aes(word,n)) + 
  geom_col() +
  xlab(NULL) +
  coord_flip()</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Vamos a hacer un gráfico que sirva para comparar la frecuencia relativa de palabras por categoría tomando como referencia la categoría más común que es <em>toys games</em></p>
<pre class="r"><code>frequencia &lt;- palabras %&gt;% 
  count(cat1,word) %&gt;% 
  group_by(cat1) %&gt;% 
  mutate(proporcion = n/sum(n)) %&gt;% 
  select(-n) %&gt;% 
  pivot_wider(names_from = &quot;cat1&quot;, values_from = &quot;proporcion&quot;) %&gt;% 
  pivot_longer(`baby products`:`pet supplies`,names_to = &quot;cat1&quot;,
               values_to = &quot;proporcion&quot;)</code></pre>
<pre class="r"><code>ggplot(frequencia, aes(x = proporcion, y = `toys games`, 
                      color = abs(`toys games` - proporcion))) +
  geom_abline(color = &quot;gray40&quot;, lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001),
                       low = &quot;darkslategray4&quot;, high = &quot;gray75&quot;) +
  facet_wrap(~cat1, ncol = 2) +
  theme(legend.position = &quot;none&quot;) +
  labs(y = &quot;toys games&quot;, x = NULL) </code></pre>
<pre><code>## Warning: Removed 178925 rows containing missing values (geom_point).</code></pre>
<pre><code>## Warning: Removed 178925 rows containing missing values (geom_text).</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>También podemos calcular explícitamente la correlación para cada par de variables:</p>
<pre class="r"><code>cor.test(data = frequencia[frequencia$cat1 == &quot;baby products&quot;,],
         ~ proporcion + `toys games`)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  proporcion and toys games
## t = 54.371, df = 6086, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.5546263 0.5884487
## sample estimates:
##       cor 
## 0.5717804</code></pre>
<pre class="r"><code>cor.test(data = frequencia[frequencia$cat1 == &quot;beauty&quot;,],
         ~ proporcion + `toys games`)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  proporcion and toys games
## t = 26.511, df = 5463, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.3139132 0.3609000
## sample estimates:
##       cor 
## 0.3376169</code></pre>
<pre class="r"><code>cor.test(data = frequencia[frequencia$cat1 == &quot;grocery gourmet food&quot;,],
         ~ proporcion + `toys games`)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  proporcion and toys games
## t = 26.196, df = 4350, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.3431868 0.3945191
## sample estimates:
##       cor 
## 0.3691345</code></pre>
<pre class="r"><code>cor.test(data = frequencia[frequencia$cat1 == &quot;health personal care&quot;,],
         ~ proporcion + `toys games`)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  proporcion and toys games
## t = 45.168, df = 7292, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4494394 0.4853086
## sample estimates:
##       cor 
## 0.4675665</code></pre>
<pre class="r"><code>cor.test(data = frequencia[frequencia$cat1 == &quot;pet supplies&quot;,],
         ~ proporcion + `toys games`)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  proporcion and toys games
## t = 40.401, df = 5974, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.4430950 0.4829279
## sample estimates:
##       cor 
## 0.4632453</code></pre>
</div>
<div id="analizando-la-frequencia-de-palabras" class="section level1">
<h1><span class="header-section-number">3</span> Analizando la frequencia de palabras</h1>
<p>Vamos a calcular el estadístico <em>tf-idf</em> para las diferentes palabras en las categorías.</p>
<p>Primero, contamos la frecuencia de las palabras en cada una de las categorías:</p>
<pre class="r"><code>palabras_cat1 &lt;- text_cat1 %&gt;%
  unnest_tokens(word,text) %&gt;% 
  count(cat1,word, sort = TRUE)

# Lo mismo que
# palabras2 &lt;- text_cat1 %&gt;%
#   unnest_tokens(word,text) %&gt;%
#   group_by(cat1,word) %&gt;% 
#   tally(sort = TRUE)

glimpse(palabras_cat1)</code></pre>
<pre><code>## Rows: 80,977
## Columns: 3
## $ cat1 &lt;chr&gt; &quot;toys games&quot;, &quot;health personal care&quot;, &quot;health personal care&quot;, &quot;b…
## $ word &lt;chr&gt; &quot;the&quot;, &quot;the&quot;, &quot;i&quot;, &quot;the&quot;, &quot;and&quot;, &quot;it&quot;, &quot;to&quot;, &quot;and&quot;, &quot;the&quot;, &quot;a&quot;, …
## $ n    &lt;int&gt; 21883, 17285, 14290, 13892, 13484, 12198, 11334, 11128, 11057, 1…</code></pre>
<p>Luego calculamos el total de palabras en cada categoría:</p>
<pre class="r"><code>total_palabras &lt;- palabras_cat1 %&gt;% 
  group_by(cat1) %&gt;% 
  summarize(total = sum(n))</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code>total_palabras</code></pre>
<pre><code>## # A tibble: 6 x 2
##   cat1                  total
##   &lt;chr&gt;                 &lt;int&gt;
## 1 baby products        270027
## 2 beauty               218183
## 3 grocery gourmet food 121393
## 4 health personal care 389766
## 5 pet supplies         218906
## 6 toys games           439719</code></pre>
<p>y finalmente, unimos ambos conjuntos:</p>
<pre class="r"><code>palabras_cat1 &lt;- left_join(palabras_cat1,total_palabras)</code></pre>
<pre><code>## Joining, by = &quot;cat1&quot;</code></pre>
<pre class="r"><code>palabras_cat1</code></pre>
<pre><code>## # A tibble: 80,977 x 4
##    cat1                 word      n  total
##    &lt;chr&gt;                &lt;chr&gt; &lt;int&gt;  &lt;int&gt;
##  1 toys games           the   21883 439719
##  2 health personal care the   17285 389766
##  3 health personal care i     14290 389766
##  4 baby products        the   13892 270027
##  5 toys games           and   13484 439719
##  6 toys games           it    12198 439719
##  7 toys games           to    11334 439719
##  8 health personal care and   11128 389766
##  9 pet supplies         the   11057 218906
## 10 toys games           a     10711 439719
## # … with 80,967 more rows</code></pre>
<p>Podemos visualizar la frecuencia relativa de las palabras por categoría así:</p>
<pre class="r"><code>ggplot(palabras_cat1, aes(n/total, fill = cat1)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA,0.0009) +
  facet_wrap(~cat1, ncol = 2, scales = &quot;free_y&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<pre><code>## Warning: Removed 936 rows containing non-finite values (stat_bin).</code></pre>
<pre><code>## Warning: Removed 6 rows containing missing values (geom_bar).</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Ya tenemos todo lo necesario para calcular <em>tf-idf</em></p>
<pre class="r"><code>palabras_cat1 &lt;- palabras_cat1 %&gt;% 
  bind_tf_idf(word, cat1, n)

palabras_cat1 &lt;- left_join(palabras_cat1,total_palabras)</code></pre>
<pre><code>## Joining, by = c(&quot;cat1&quot;, &quot;total&quot;)</code></pre>
<p>Mejor si lo ordenamos en orden descendente:</p>
<pre class="r"><code>palabras_cat1 &lt;- palabras_cat1 %&gt;% 
  bind_tf_idf(word, cat1, n) %&gt;% 
  select(-total) %&gt;%
  arrange(desc(tf_idf))

palabras_cat1</code></pre>
<pre><code>## # A tibble: 80,977 x 6
##    cat1                 word       n       tf   idf   tf_idf
##    &lt;chr&gt;                &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 toys games           toy     2385 0.00542  0.182 0.000989
##  2 health personal care shaver   337 0.000865 1.10  0.000950
##  3 pet supplies         litter   500 0.00228  0.405 0.000926
##  4 grocery gourmet food sauce    162 0.00133  0.693 0.000925
##  5 grocery gourmet food flour     50 0.000412 1.79  0.000738
##  6 health personal care braun    157 0.000403 1.79  0.000722
##  7 health personal care shave    399 0.00102  0.693 0.000710
##  8 toys games           game    1647 0.00375  0.182 0.000683
##  9 baby products        crib     166 0.000615 1.10  0.000675
## 10 grocery gourmet food flavor   441 0.00363  0.182 0.000662
## # … with 80,967 more rows</code></pre>
<p>y ahora podemos visualizar digamos las 10 más importantes por grupo</p>
<pre class="r"><code>palabras_cat1 %&gt;%
  arrange(desc(tf_idf)) %&gt;%
  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% 
  group_by(cat1) %&gt;% 
  top_n(10,wt = tf_idf) %&gt;% 
  ungroup() %&gt;%
  ggplot(aes(word, tf_idf, fill = cat1)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = &quot;tf-idf&quot;) +
  facet_wrap(~cat1, ncol = 2, scales = &quot;free&quot;) +
  coord_flip()</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="relaciones-entre-palabras-n-gramas-y-correlaciones" class="section level1">
<h1><span class="header-section-number">4</span> Relaciones entre palabras n-gramas y correlaciones</h1>
<p>Tokenizamos por bigramas esta vez:</p>
<pre class="r"><code>bigramas &lt;- text_cat1 %&gt;%
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2)</code></pre>
<p>y calculamos su frequencia</p>
<pre class="r"><code>bigramas %&gt;% 
  count(bigram, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 443,357 x 2
##    bigram           n
##    &lt;chr&gt;        &lt;int&gt;
##  1 of the        5744
##  2 in the        4886
##  3 i have        4865
##  4 it is         4822
##  5 is a          3568
##  6 on the        3369
##  7 this is       3245
##  8 and i         3177
##  9 this product  3042
## 10 and the       2963
## # … with 443,347 more rows</code></pre>
<p>los separamos para poder excluir los que contienen palabras vacías</p>
<pre class="r"><code>bigramas_separados &lt;- bigramas %&gt;% 
  separate(bigram, c(&quot;palabra1&quot;,&quot;palabra2&quot;), sep = &quot; &quot;) 

bigramas_filtrados &lt;- bigramas_separados %&gt;% 
  filter(!palabra1 %in% stop_words$word) %&gt;% 
  filter(!palabra2 %in% stop_words$word)

bigramas_filtrados</code></pre>
<pre><code>## # A tibble: 161,671 x 5
##    product_id cat1                    id palabra1   palabra2   
##    &lt;chr&gt;      &lt;chr&gt;                &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;      
##  1 B0000017QN health personal care  9869 sedona     suite.i    
##  2 B0000017QN health personal care  9869 suite.i    love       
##  3 B0000017QN health personal care  9869 soothing   synthesizer
##  4 B0000017QN health personal care  9869 muted      joy        
##  5 B0000017QN health personal care  9869 joy        comparable 
##  6 B0000017QN health personal care  9869 wedding    notices    
##  7 B0000017QN health personal care  9869 local      paper      
##  8 B0000017QN health personal care  9869 album      delivers   
##  9 B0000017QN health personal care  9869 substitute federal    
## 10 B0000017QN health personal care  9869 federal    holiday    
## # … with 161,661 more rows</code></pre>
<p>y calculamos su frecuencia</p>
<pre class="r"><code>cuenta_bigramas &lt;- bigramas_filtrados %&gt;% 
  count(palabra1,palabra2,sort = TRUE)

cuenta_bigramas</code></pre>
<pre><code>## # A tibble: 111,801 x 3
##    palabra1 palabra2        n
##    &lt;chr&gt;    &lt;chr&gt;       &lt;int&gt;
##  1 highly   recommend     673
##  2 1        2             343
##  3 car      seat          227
##  4 6        months        196
##  5 son      loves         177
##  6 litter   box           153
##  7 5        stars         152
##  8 3        months        151
##  9 customer service       139
## 10 highly   recommended   127
## # … with 111,791 more rows</code></pre>
<p>Los unimos de nuevo y calculamos su tf_idf</p>
<pre class="r"><code>bigramas_unidos &lt;- bigramas_filtrados %&gt;% 
  unite(bigram, palabra1, palabra2, sep = &quot; &quot;)</code></pre>
<pre class="r"><code>bigramas_tf_idf &lt;- bigramas_unidos %&gt;%
  count(cat1,bigram) %&gt;% 
  bind_tf_idf(bigram,cat1,n) %&gt;% 
  arrange(desc(tf_idf))

bigramas_tf_idf</code></pre>
<pre><code>## # A tibble: 122,550 x 6
##    cat1                 bigram            n      tf   idf  tf_idf
##    &lt;chr&gt;                &lt;chr&gt;         &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 pet supplies         litter box      152 0.00740  1.10 0.00813
##  2 grocery gourmet food gluten free      76 0.00493  1.10 0.00542
##  3 beauty               flat iron        68 0.00302  1.79 0.00541
##  4 baby products        baby dry         60 0.00260  1.79 0.00466
##  5 pet supplies         dog food         47 0.00229  1.79 0.00410
##  6 beauty               hair dryer       51 0.00227  1.79 0.00406
##  7 beauty               curling iron     44 0.00195  1.79 0.00350
##  8 baby products        avent bottles    42 0.00182  1.79 0.00326
##  9 pet supplies         gentle leader    36 0.00175  1.79 0.00314
## 10 pet supplies         cats love        35 0.00170  1.79 0.00305
## # … with 122,540 more rows</code></pre>
</div>
<div id="modelado-de-temas-usando-lda" class="section level1">
<h1><span class="header-section-number">5</span> Modelado de temas usando LDA</h1>
<p>Regresamos a la lista de palabras con su frecuencia y sin palabras vacías:</p>
<pre class="r"><code>palabras_tidy &lt;- text_cat1 %&gt;%
  unnest_tokens(word,text) %&gt;%
   anti_join(stop_words) %&gt;% 
  count(id,word, sort = TRUE) </code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre class="r"><code>palabras_tidy</code></pre>
<pre><code>## # A tibble: 479,761 x 3
##       id word       n
##    &lt;int&gt; &lt;chr&gt;  &lt;int&gt;
##  1   274 eacute    38
##  2 14702 bed       34
##  3 15303 hair      26
##  4  7518 seat      24
##  5 16935 bath      24
##  6 10290 hair      23
##  7  8784 unit      22
##  8 15685 food      21
##  9 18170 baby      21
## 10  3037 tea       20
## # … with 479,751 more rows</code></pre>
<p>Para hacer el LDA se usa la librería <code>tm</code> que requiere la información en un formato de matriz de términos del documento. Eso es lo que hacemos en este paso:</p>
<pre class="r"><code>dtm_palabras &lt;- palabras_tidy %&gt;% 
  cast_tdm(id,word,n)</code></pre>
<p>Con la función <code>LDA</code> creamos un modelo de 6 términos:</p>
<pre class="r"><code>review_lda &lt;- LDA(dtm_palabras, k = 6, control = list(seed = 1234))</code></pre>
<p>Ahora, se pueden examinar las probabilidades asociadas a cada palabra por tópico</p>
<pre class="r"><code>review_topics &lt;- tidy(review_lda, matrix = &quot;beta&quot;)
review_topics</code></pre>
<pre><code>## # A tibble: 249,720 x 3
##    topic term       beta
##    &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1     1 eacute 1.31e-11
##  2     2 eacute 1.63e- 9
##  3     3 eacute 5.64e- 4
##  4     4 eacute 3.35e-11
##  5     5 eacute 1.79e-12
##  6     6 eacute 4.73e-11
##  7     1 bed    6.22e- 4
##  8     2 bed    3.10e- 5
##  9     3 bed    6.66e- 4
## 10     4 bed    3.77e- 3
## # … with 249,710 more rows</code></pre>
<p>Podemos hallar cuales son las palabras más comunes por cada tema:</p>
<pre class="r"><code>review_top_terms &lt;- review_topics %&gt;%
  group_by(topic) %&gt;%
  top_n(5, beta) %&gt;%
  ungroup() %&gt;%
  arrange(topic, -beta)

review_top_terms</code></pre>
<pre><code>## # A tibble: 30 x 3
##    topic term       beta
##    &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1     1 time    0.0126 
##  2     1 product 0.0121 
##  3     1 toy     0.00902
##  4     1 play    0.00837
##  5     1 price   0.00595
##  6     2 toy     0.0124 
##  7     2 product 0.00924
##  8     2 love    0.00883
##  9     2 time    0.00701
## 10     2 day     0.00657
## # … with 20 more rows</code></pre>
<p>Visualmente:</p>
<pre class="r"><code>review_top_terms %&gt;%
  mutate(term = reorder_within(term, beta, topic)) %&gt;%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = &quot;free&quot;) +
  coord_flip() +
  scale_x_reordered()</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<div id="clasificación-de-las-revisiones" class="section level2">
<h2><span class="header-section-number">5.1</span> Clasificación de las revisiones</h2>
<p>Calculamos la probabilidad por documento y por tema. En este caso, cada documento constituye una revisión.</p>
<pre class="r"><code>review_topics_gamma &lt;- tidy(review_lda, matrix = &quot;gamma&quot;)

review_topics_gamma &lt;- review_topics_gamma %&gt;% 
  mutate(id = as.numeric(document))</code></pre>
<p>Para tratar de determinar hasta que punto los tópicos detectados corresponden a las clasificaciones de <code>cat1</code> vamos a combinar la información de ambos en <code>cat1_gamma</code> y a visualizarlos:</p>
<pre class="r"><code>cat1_gamma &lt;- left_join(review_topics_gamma,text_cat1) </code></pre>
<pre><code>## Joining, by = &quot;id&quot;</code></pre>
<pre class="r"><code>cat1_gamma %&gt;%
  mutate(cat1 = reorder(cat1, gamma * topic)) %&gt;%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot(outlier.alpha = 0.3) +
  facet_wrap(~ cat1)</code></pre>
<p><img src="01_intro_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Veamos cual es el tópico más asociado a cada categoría</p>
<pre class="r"><code>cat1_classifications &lt;- cat1_gamma %&gt;%
  group_by(cat1, id) %&gt;%
  top_n(1, gamma) %&gt;%
  ungroup()

cat1_topics &lt;- cat1_classifications %&gt;%
  count(cat1, topic) %&gt;%
  group_by(cat1) %&gt;%
  top_n(1, n) %&gt;%
  ungroup() %&gt;%
  transmute(consensus = cat1, topic)</code></pre>
<p>Podemos calcular cual es el tṕico más frecuente o común en cada una de las categorías</p>
<pre class="r"><code>cat1_topics &lt;- cat1_classifications %&gt;%
  count(cat1, topic) %&gt;%
  group_by(cat1) %&gt;%
  top_n(1, n) %&gt;%
  ungroup() %&gt;%
  transmute(consensus = cat1, topic)

cat1_topics</code></pre>
<pre><code>## # A tibble: 6 x 2
##   consensus            topic
##   &lt;chr&gt;                &lt;int&gt;
## 1 baby products            2
## 2 beauty                   6
## 3 grocery gourmet food     5
## 4 health personal care     3
## 5 pet supplies             6
## 6 toys games               1</code></pre>
<p>y al unirlo con las <code>cat1_classifications</code> podemos ver cuales observaciones se encuentran incorrectamente clasificadas:</p>
<pre class="r"><code>cat1_classifications %&gt;% 
  inner_join(cat1_topics, by = &quot;topic&quot;) %&gt;% 
  filter(cat1 != consensus)</code></pre>
<pre><code>## # A tibble: 14,888 x 8
##    document topic gamma    id product_id text                 cat1     consensus
##    &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                &lt;chr&gt;    &lt;chr&gt;    
##  1 19059        1 0.201 19059 B000CEM36I &quot;Cascade manufactur… health … toys gam…
##  2 9780         1 0.207  9780 B0002KHTZ2 &quot;I know a lot of pe… health … toys gam…
##  3 11176        1 0.205 11176 B000KVWNEK &quot;I moved back home … pet sup… toys gam…
##  4 14898        1 0.384 14898 B000JZ5CQS &quot;As of August 17, 2… grocery… toys gam…
##  5 19457        1 0.198 19457 B0000649E1 &quot;My aunt uses these… baby pr… toys gam…
##  6 9911         1 0.193  9911 B000P26UEI &quot;We bought the fill… baby pr… toys gam…
##  7 14997        1 0.303 14997 B0009YUEG2 &quot;I love this litter… pet sup… toys gam…
##  8 3527         1 0.271  3527 B000EM6PC6 &quot;There are several … grocery… toys gam…
##  9 9409         1 0.209  9409 B0002G3UY0 &quot;I&#39;ve drank a few b… grocery… toys gam…
## 10 9694         1 0.183  9694 B000CMF1A0 &quot;I was SO excited t… grocery… toys gam…
## # … with 14,878 more rows</code></pre>
<pre class="r"><code>cat1_classifications</code></pre>
<pre><code>## # A tibble: 19,992 x 7
##    document topic gamma    id product_id text                          cat1     
##    &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;                         &lt;chr&gt;    
##  1 14964        1 0.215 14964 B0006N8XZK &quot;I initially bought this toy… toys gam…
##  2 19059        1 0.201 19059 B000CEM36I &quot;Cascade manufactures a grea… health p…
##  3 9780         1 0.207  9780 B0002KHTZ2 &quot;I know a lot of people comp… health p…
##  4 10992        1 0.251 10992 B000ETREQA &quot;My kids (4 and 7) did learn… toys gam…
##  5 11176        1 0.205 11176 B000KVWNEK &quot;I moved back home to my mot… pet supp…
##  6 14898        1 0.384 14898 B000JZ5CQS &quot;As of August 17, 2008; all … grocery …
##  7 19457        1 0.198 19457 B0000649E1 &quot;My aunt uses these diapers … baby pro…
##  8 9911         1 0.193  9911 B000P26UEI &quot;We bought the filled baby b… baby pro…
##  9 14997        1 0.303 14997 B0009YUEG2 &quot;I love this litter because.… pet supp…
## 10 17948        1 0.224 17948 B000PC51LQ &quot;The Smart Splash Sail Away … toys gam…
## # … with 19,982 more rows</code></pre>
</div>
</div>
<div id="a-manera-de-conclusiones" class="section level1">
<h1><span class="header-section-number">6</span> A manera de conclusiones</h1>
<ul>
<li><p>Es posible detectar diferencias en las palabras usadas por categoría usando tf-idf</p></li>
<li><p>Sin embargo, el modelo LDA no parece separar muy bien las diferentes categorías</p></li>
</ul>
<p>Próxima vez:</p>
<ul>
<li>Comenzar con un primer modelo supervisado</li>
</ul>
</div>

<div id="rmd-source-code">---
title: "Análisis exploratorio de datos"
subtitle: "Amazon reviews"
author: "Magdiel Ablan"
date: "8/12/2020"
output: 
    html_document: 
      code_download: true 
      number_sections: yes
      code_folding: hide
      theme: lumen
      toc: yes
      toc_float:
        collapsed: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
library(tidyverse)
library(tidytext)
library(readr)
library(janitor)
library(scales)
library(widyr)
library(topicmodels)
```

# Introducción

A continuación realizamos un análisis exploratorio de datos
del conjunto de datos de [revisión de
productos de Amazon](https://www.kaggle.com/kashnitsky/hierarchical-text-classification) que se encuentra en Kaggle.

La idea es usar este conjunto de datos como un *proxy* que permita
aproximarnos al problema de clasificar documentos planteado en el proyecto **iconos**.

Este conjunto de datos tiene tres niveles  o categorías de
clasificación:

1. Nivel 1: 6 clases
2. Nivel 2: 64 clases
3. Nivel 3: 510 clases 

y tres conjuntos de datos:

 - train_40k.csv: para entrenamiento 40000 registros
 - valid_10k.csv: para validación 10000 registros
 - unlabeled_150k.csv: 150000 registros sin etiqueta 

El análisis exploratorio lo vamos a realizar con el 
conjunto de entrenamiento y por el momento con el primer
nivel de clasificación.

Las variables que tiene son:

 - product_id
 - title
 - user_id
 - helpfulness
 - score
 - time
 - text
 - cat1
 - cat2
 - cat3

# Ingestión de datos

```{r}
train_40k <- read_csv("datos/train_40k.csv") %>% 
  clean_names()
glimpse(train_40k)
```

Para evitar problemas de memoria más adelante, se crea una muestra
de 20000 observaciones del conjunto de entrenamiento. Con eso vamos a trabajar:

```{r}
set.seed(1234)
ind_20k <- sample(1:40000,size = 20000,replace = FALSE)
train_20k <- train_40k[ind_20k,]
```

Añadimos un `id` a los registros y seleccionamos solo el texto y la categoría 1

```{r}
n_reviews <- dim(train_20k)[1]
id <- 1:n_reviews

text_cat1 <- train_20k %>%
  select(product_id,text,cat1) %>% 
  mutate(id = id)

glimpse(text_cat1)
```

Contamos cuantos registros tenemos en cada categoría: 
```{r}
text_cat1 %>% 
  group_by(cat1) %>% 
  tally()
```


Extraemos las palabras en el texto:
```{r}
palabras <- text_cat1 %>%
  unnest_tokens(word,text)

glimpse(palabras)
```

y excluimos las palabras vacías 
```{r}
data(stop_words)
palabras <- palabras %>% 
  anti_join(stop_words)

```

Calculamos la frecuencia de palabras en orden descendente
```{r}
palabras %>% 
  count(word, sort = TRUE)

```

y las visualizamos:

```{r}
palabras %>% 
  count(word, sort = TRUE) %>% 
  filter(n > 2000) %>% 
  mutate(word = reorder(word,n)) %>% 
  ggplot(aes(word,n)) + 
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

Vamos a hacer un gráfico que sirva para comparar la frecuencia relativa de palabras por categoría tomando como referencia la categoría más común que es *toys games*  

```{r}
frequencia <- palabras %>% 
  count(cat1,word) %>% 
  group_by(cat1) %>% 
  mutate(proporcion = n/sum(n)) %>% 
  select(-n) %>% 
  pivot_wider(names_from = "cat1", values_from = "proporcion") %>% 
  pivot_longer(`baby products`:`pet supplies`,names_to = "cat1",
               values_to = "proporcion")
```

```{r}
ggplot(frequencia, aes(x = proporcion, y = `toys games`, 
                      color = abs(`toys games` - proporcion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001),
                       low = "darkslategray4", high = "gray75") +
  facet_wrap(~cat1, ncol = 2) +
  theme(legend.position = "none") +
  labs(y = "toys games", x = NULL) 

```

También podemos calcular explícitamente la correlación para
cada par de variables:

```{r}
cor.test(data = frequencia[frequencia$cat1 == "baby products",],
         ~ proporcion + `toys games`)

cor.test(data = frequencia[frequencia$cat1 == "beauty",],
         ~ proporcion + `toys games`)

cor.test(data = frequencia[frequencia$cat1 == "grocery gourmet food",],
         ~ proporcion + `toys games`)

cor.test(data = frequencia[frequencia$cat1 == "health personal care",],
         ~ proporcion + `toys games`)

cor.test(data = frequencia[frequencia$cat1 == "pet supplies",],
         ~ proporcion + `toys games`)


```

# Analizando la frequencia de palabras

Vamos a calcular el estadístico *tf-idf* para las diferentes
palabras en las categorías.

Primero, contamos la frecuencia de las palabras en cada una
de las categorías:

```{r}
palabras_cat1 <- text_cat1 %>%
  unnest_tokens(word,text) %>% 
  count(cat1,word, sort = TRUE)

# Lo mismo que
# palabras2 <- text_cat1 %>%
#   unnest_tokens(word,text) %>%
#   group_by(cat1,word) %>% 
#   tally(sort = TRUE)

glimpse(palabras_cat1)


```

Luego calculamos el total de palabras en cada categoría:
```{r}
total_palabras <- palabras_cat1 %>% 
  group_by(cat1) %>% 
  summarize(total = sum(n))

total_palabras
```

y finalmente, unimos ambos conjuntos:

```{r}
palabras_cat1 <- left_join(palabras_cat1,total_palabras)

palabras_cat1
```

Podemos visualizar la frecuencia relativa de las palabras por
categoría así:

```{r}
ggplot(palabras_cat1, aes(n/total, fill = cat1)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA,0.0009) +
  facet_wrap(~cat1, ncol = 2, scales = "free_y")

```

Ya tenemos todo lo necesario para calcular *tf-idf*
```{r}
palabras_cat1 <- palabras_cat1 %>% 
  bind_tf_idf(word, cat1, n)

palabras_cat1 <- left_join(palabras_cat1,total_palabras)

```

Mejor si lo ordenamos en orden descendente:
```{r}
palabras_cat1 <- palabras_cat1 %>% 
  bind_tf_idf(word, cat1, n) %>% 
  select(-total) %>%
  arrange(desc(tf_idf))

palabras_cat1
```

y ahora podemos visualizar digamos las 10 más importantes
por grupo

```{r}
palabras_cat1 %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(cat1) %>% 
  top_n(10,wt = tf_idf) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = cat1)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~cat1, ncol = 2, scales = "free") +
  coord_flip()
```

# Relaciones entre palabras n-gramas y correlaciones

Tokenizamos por bigramas esta vez:
```{r}
bigramas <- text_cat1 %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)
```

y calculamos su frequencia
```{r}
bigramas %>% 
  count(bigram, sort = TRUE)
```

los separamos para poder excluir los que contienen palabras vacías
```{r}
bigramas_separados <- bigramas %>% 
  separate(bigram, c("palabra1","palabra2"), sep = " ") 

bigramas_filtrados <- bigramas_separados %>% 
  filter(!palabra1 %in% stop_words$word) %>% 
  filter(!palabra2 %in% stop_words$word)

bigramas_filtrados
```

y calculamos su frecuencia
```{r}
cuenta_bigramas <- bigramas_filtrados %>% 
  count(palabra1,palabra2,sort = TRUE)

cuenta_bigramas
```

Los unimos de nuevo y calculamos su tf_idf
```{r}
bigramas_unidos <- bigramas_filtrados %>% 
  unite(bigram, palabra1, palabra2, sep = " ")

```

```{r}
bigramas_tf_idf <- bigramas_unidos %>%
  count(cat1,bigram) %>% 
  bind_tf_idf(bigram,cat1,n) %>% 
  arrange(desc(tf_idf))

bigramas_tf_idf
```

# Modelado de temas usando LDA

Regresamos a la lista de palabras con su frecuencia y sin palabras vacías:

```{r}
palabras_tidy <- text_cat1 %>%
  unnest_tokens(word,text) %>%
   anti_join(stop_words) %>% 
  count(id,word, sort = TRUE) 
 

palabras_tidy


```

Para hacer el LDA se usa la librería `tm` que requiere la información
en un formato de matriz de términos del documento. Eso es lo que hacemos
en este paso:

```{r}
dtm_palabras <- palabras_tidy %>% 
  cast_tdm(id,word,n)

```

Con la función `LDA` creamos un modelo de 6 términos:
```{r}
review_lda <- LDA(dtm_palabras, k = 6, control = list(seed = 1234))
```

Ahora, se pueden examinar las probabilidades asociadas a cada palabra 
por tópico

```{r}
review_topics <- tidy(review_lda, matrix = "beta")
review_topics
```

Podemos hallar cuales son las palabras más comunes por cada tema:

```{r}
review_top_terms <- review_topics %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

review_top_terms
```

Visualmente:

```{r}
review_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

```

## Clasificación de las revisiones

Calculamos la probabilidad por documento y por tema. En este caso, cada documento constituye una revisión. 

```{r}
review_topics_gamma <- tidy(review_lda, matrix = "gamma")

review_topics_gamma <- review_topics_gamma %>% 
  mutate(id = as.numeric(document))
```

Para tratar de determinar hasta que punto los tópicos detectados corresponden a las clasificaciones de `cat1` vamos a combinar la información de ambos en `cat1_gamma` y a visualizarlos:

```{r}
cat1_gamma <- left_join(review_topics_gamma,text_cat1) 


cat1_gamma %>%
  mutate(cat1 = reorder(cat1, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot(outlier.alpha = 0.3) +
  facet_wrap(~ cat1)


```

Veamos cual es el tópico más asociado a cada categoría
```{r}
cat1_classifications <- cat1_gamma %>%
  group_by(cat1, id) %>%
  top_n(1, gamma) %>%
  ungroup()

cat1_topics <- cat1_classifications %>%
  count(cat1, topic) %>%
  group_by(cat1) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = cat1, topic)



```

Podemos calcular cual es el tṕico más frecuente o común en
cada una de las categorías

```{r}
cat1_topics <- cat1_classifications %>%
  count(cat1, topic) %>%
  group_by(cat1) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = cat1, topic)

cat1_topics

```

y al unirlo con las `cat1_classifications` podemos ver cuales
observaciones se encuentran incorrectamente clasificadas:

```{r}
cat1_classifications %>% 
  inner_join(cat1_topics, by = "topic") %>% 
  filter(cat1 != consensus)

cat1_classifications
```



# A manera de conclusiones

 * Es posible detectar diferencias en las palabras usadas por
categoría usando tf-idf

 * Sin embargo, el modelo LDA no parece separar muy bien las diferentes
categorías

Próxima vez:

* Comenzar con un primer modelo supervisado
 

</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("01_intro.Rmd");
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
